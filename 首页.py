import streamlit as st
import action
import models
import logging
logging.basicConfig(level=logging.INFO,
                    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')


with open('key.txt', 'r') as f:
    st.session_state.base_url = f.readline().strip()  # è¯»å–ç¬¬ä¸€è¡Œå¹¶å»é™¤å¯èƒ½çš„å‰åç©ºæ ¼æˆ–æ¢è¡Œ
    st.session_state.key = f.readline().strip() 
    st.session_state.model=f.readline().strip()
#models.setup_database()
st.sidebar.markdown("# é¦–é¡µ ğŸˆ")
logging.info(f"é¦–é¡µopenaiapi-url: {st.session_state.base_url}")
logging.info(f"é¦–é¡µopenaiapi-key: {st.session_state.key}")
logging.info(f"é¦–é¡µopenaiapi-modle: {st.session_state.model}")


placeholder = st.empty()
wordlist = models.get_all_words()
placeholder.header(f'welcome! you have lenarned {len(models.get_all_words())} words')

# è·å–ç”¨æˆ·è¾“å…¥
word = st.text_input('è¯·è¾“å…¥å•è¯:')
user_input = word


if user_input=='':
    pass
else:
    #word=""
    #st.experimental_rerun()
    print(user_input)
    example=action.process_word(user_input)
    logging.info(f'''é¦–é¡µè·å–çš„exampleï¼š{example}''')
    st.title(user_input)
    st.text(f'''è¯é¢‘:{example.get('frequency')}''')
    st.caption('ä¸­æ–‡ï¼š')
    st.subheader(f'''{example.get('chinese_translation')}''')
    st.caption('ä¾‹å¥ï¼š')
    st.subheader(f'''{example.get('example_sentence')}''')
    roots=example.get('roots')
    print(roots)
    if not roots:
        st.write('æ²¡æœ‰è¯æ ¹')
    else:
        st.caption('è¯æ ¹ï¼š')
        for root in roots:
            st.subheader(f'''{root.get('text')+'    '+root.get('chinese_translation')}''')
    prefixes=example.get('prefixes')
    if not prefixes:
        st.write('æ²¡æœ‰è¯å‰ç¼€')
    else:
        st.caption('å‰ç¼€ï¼š')
        for prefix in prefixes:
            st.subheader(f'''{prefix.get('text')+'    '+prefix.get('chinese_translation')}''')
    suffixes=example.get('suffixes')
    if not suffixes:
        st.write('æ²¡æœ‰è¯åç¼€')
    else:
        st.caption('åç¼€ï¼š')
        for suffix in suffixes:
            st.subheader(f'''{suffix.get('text')+'    '+suffix.get('chinese_translation')}''')
    wordlist = models.get_all_words()
    placeholder.header(f'welcome! you have lenarned {len(models.get_all_words())} words')
